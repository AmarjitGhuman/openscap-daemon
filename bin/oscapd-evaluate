#!/usr/bin/python

# Copyright 2016 Red Hat Inc., Durham, North Carolina.
# All Rights Reserved.
#
# openscap-daemon is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 2.1 of the License, or
# (at your option) any later version.
#
# openscap-daemon is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.

# You should have received a copy of the GNU Lesser General Public License
# along with openscap-daemon.  If not, see <http://www.gnu.org/licenses/>.
#
# Authors:
#   Martin Preisler <mpreisle@redhat.com>

from openscap_daemon import config as config_
from openscap_daemon import evaluation_spec
from openscap_daemon import oscap_helpers
from openscap_daemon import version

import os
import os.path
import logging
import argparse
import sys
import threading
import io
import json
import datetime
from xml.etree import cElementTree as ElementTree

if sys.version_info < (3,):
    import Queue
else:
    import queue as Queue


def preprocess_targets(targets):
    """The main goal of this function is to expand chroots-in-dir:// to a list
    of chroot:// targets. chroots-in-dir is a convenience function that the rest
    of the OpenSCAP-daemon API doesn't know about.
    """

    ret = []

    for target in targets:
        if target.startswith("chroots-in-dir://"):
            logging.debug("Expanding target '%s'...", target)

            dir_ = os.path.abspath(target[len("chroots-in-dir://"):])
            for chroot in os.listdir(dir_):
                full_path = os.path.abspath(os.path.join(dir_, chroot))

                if not os.path.isdir(full_path):
                    continue

                expanded_target = "chroot://" + full_path
                logging.debug(" ... '%s'", expanded_target)
                ret.append(expanded_target)

            logging.debug("Finished expanding target '%s'.", target)

        else:
            ret.append(target)

    return ret


def summarize_cve_results(oval_source, result_list):
    namespaces = {
        "ovalres": "http://oval.mitre.org/XMLSchema/oval-results-5",
        "ovaldef": "http://oval.mitre.org/XMLSchema/oval-definitions-5"
    }

    oval_root = ElementTree.fromstring(oval_source.encode("utf-8"))

    for result in oval_root.findall(
            "ovalres:results/ovalres:system/"
            "ovalres:definitions/*[@result='true']",
            namespaces):
        definition_id = result.get("definition_id")
        assert(definition_id is not None)

        definition_meta = oval_root.find(
            "./ovaldef:oval_definitions/ovaldef:definitions/*[@id='%s']/"
            "ovaldef:metadata" % (definition_id),
            namespaces
        )
        assert(definition_meta is not None)

        title = definition_meta.find("ovaldef:title", namespaces)
        # there can only be one RHSA per definition
        rhsa = definition_meta.find("ovaldef:reference[@source='RHSA']",
                                    namespaces)
        # there can be one or more CVEs per definition
        cves = definition_meta.findall("ovaldef:reference[@source='CVE']",
                                       namespaces)
        description = definition_meta.find("ovaldef:description", namespaces)
        severity = definition_meta.find("ovaldef:severity", namespaces)

        # report the vulnerabilities one CVE at a time
        # (if one RHSA fixes multiple CVEs it will be reported multiple times)
        for cve in cves:
            result_json = {}
            result_json["Title"] = cve.get("ref_id")
            result_json["Fail"] = "true"
            result_json["RHSA"] = rhsa.get("ref_id")
            result_json["CVE"] = cve.get("ref_id")
            result_json["Short Description"] = \
                title.text if title is not None else "unknown"
            result_json["Long Description"] = \
                description.text if description is not None else "unknown"
            result_json["Severity"] = \
                severity.text if severity is not None else "unknown"
            # TODO
            #result_json["Notes"] = ""

            result_list.append(result_json)


def summarize_standard_compliance_results(arf_source, result_list):
    namespaces = {
        "cdf": "http://checklists.nist.gov/xccdf/1.2",
    }

    arf_root = ElementTree.fromstring(arf_source.encode("utf-8"))

    test_result = arf_root.find(
        ".//cdf:TestResult[@id='%s']" %
        ("xccdf_org.open-scap_testresult_xccdf_org.ssgproject.content_profile_"
         "standard"), namespaces
    )

    benchmark = arf_root.find(".//cdf:Benchmark", namespaces)

    for rule_result in test_result.findall("./cdf:rule-result", namespaces):
        result = rule_result.find("cdf:result", namespaces).text

        if result in ["pass", "fixed", "informational", "notselected",
                      "notapplicable"]:
            continue

        rule_id = rule_result.get("idref")
        assert(rule_id is not None)

        rule = benchmark.find(".//cdf:Rule[@id='%s']" % (rule_id), namespaces)
        assert(rule is not None)

        title = rule.find("cdf:title", namespaces)
        description = rule.find("cdf:description", namespaces)
        severity = rule.get("severity", "unknown")

        result_json = {}
        result_json["Title"] = title.text if title is not None else "unknown"
        result_json["Fail"] = "true"
        result_json["Short Description"] = \
            title.text if title is not None else "unknown"
        result_json["Long Description"] = \
            description.text if description is not None else "unknown"
        result_json["Severity"] = severity
        result_json["Notes"] = "XCCDF result: %s" % (result)

        result_list.append(result_json)


def main():
    parser = argparse.ArgumentParser(
        description="OpenSCAP-Daemon one-off evaluator."
    )
    parser.add_argument(
        "-v", "--version", action="version",
        version="%(prog)s " + version.VERSION_STRING
    )
    parser.add_argument("--verbose",
                        help="be verbose, useful for debugging",
                        action="store_true")

    subparsers = parser.add_subparsers(dest="action")
    subparsers.required = True

    config_parser = subparsers.add_parser(
        "config",
        help="Start with default configuration, auto-detect tool and content "
             "locations and output the resulting INI results into stdout or "
             "given file path"
    )
    config_parser.add_argument(
        "--path", metavar="PATH", type=argparse.FileType("w"),
        default=sys.stdout
    )

    xml_parser = subparsers.add_parser(
        "xml",
        help="Evaluate an EvaluationSpec passed as an XML, either to stdin or "
             "as a file"
    )
    xml_parser.add_argument(
        "--path", metavar="PATH", type=argparse.FileType("r"),
        default=sys.stdin
    )
    xml_parser.add_argument(
        "--results", metavar="PATH", type=argparse.FileType("w")
    )
    xml_parser.add_argument(
        "--stdout", metavar="PATH", type=argparse.FileType("w")
    )
    xml_parser.add_argument(
        "--stderr", metavar="PATH", type=argparse.FileType("w")
    )

    spec_parser = subparsers.add_parser(
        "spec",
        help="Evaluate an EvaluationSpec created using arguments passed on "
             "the command line."
    )
    spec_parser.add_argument(
        "--mode", type=str, choices=["sds", "oval", "cve_scan", "standard_scan"],
        default="sds"
    )
    spec_parser.add_argument(
        "--target", type=str,
        default="localhost"
    )
    spec_parser.add_argument(
        "--input", metavar="PATH", dest="input_",
        type=lambda path: io.open(path, "r", encoding="utf-8"),
        default=sys.stdin
    )
    spec_parser.add_argument(
        "--tailoring", metavar="PATH",
        type=lambda path: io.open(path, "r", encoding="utf-8"),
    )
    spec_parser.add_argument(
        "--profile", type=str,
        default=""
    )
    spec_parser.add_argument(
        "--remediate", default=False, action="store_true"
    )
    spec_parser.add_argument(
        "--print-xml",
        dest="print_xml",
        help="Don't evaluate the EvaluationSpec, just print its XML to stdout",
        action="store_true"
    )
    spec_parser.add_argument(
        "--results", metavar="PATH",
        type=lambda path: io.open(path, "w", encoding="utf-8"),

    )
    spec_parser.add_argument(
        "--stdout", metavar="PATH",
        type=lambda path: io.open(path, "w", encoding="utf-8"),
    )
    spec_parser.add_argument(
        "--stderr", metavar="PATH",
        type=lambda path: io.open(path, "w", encoding="utf-8"),
    )
    target_cpes_parser = subparsers.add_parser(
        "target-cpes",
        help="Detect CPEs applicable on given target"
    )
    target_cpes_parser.add_argument(
        "--target", type=str,
        default="localhost"
    )
    scan_parser = subparsers.add_parser(
        "scan",
        help="Scan a list of targets for CVEs and compliance with the standard "
        "profile, return aggregated results. This is an integration shim "
        "intended for Atomic but can also be useful elsewhere."
    )
    scan_parser.add_argument(
        "--targets", type=str, nargs="+",
        default=["localhost"]
    )
    scan_parser.add_argument(
        "-j", "--jobs", type=int,
        default=4
    )
    scan_parser.add_argument(
        "--no-cve-scan", default=False, action="store_true",
        dest="no_cve_scan",
        help="Skip the CVE scan."
    )
    scan_parser.add_argument(
        "--no-standard-compliance", default=False, action="store_true",
        dest="no_standard_compliance",
        help="Skip the standard profile compliance scan."
    )
    scan_parser.add_argument(
        "--output", type=str, required=True,
        help="A directory where results will be stored in."
    )
    args = parser.parse_args()

    logging.basicConfig(format='%(levelname)s:%(message)s',
                        level=logging.DEBUG if args.verbose else logging.INFO)
    logging.info("OpenSCAP Daemon one-off evaluator %s", version.VERSION_STRING)

    if args.action == "config":
        config = config_.Configuration()
        config.autodetect_tool_paths()
        config.autodetect_content_paths()
        config.save_as(args.path)
        sys.exit(0)

    config_file = os.path.join("/", "etc", "oscapd", "config.ini")
    if "OSCAPD_CONFIG_FILE" in os.environ:
        config_file = os.environ["OSCAPD_CONFIG_FILE"]

    config = config_.Configuration()
    config.load(config_file)
    config.autodetect_tool_paths()
    config.autodetect_content_paths()
    config.prepare_dirs(cleanup_allowed=False)

    if args.action == "xml":
        spec = evaluation_spec.EvaluationSpec()
        spec.load_from_xml_file(args.path)
        results, stdout, stderr, exit_code = spec.evaluate(config)
        if args.results is not None:
            args.results.write(results)
            args.results.close()
        if args.stdout is not None:
            args.stdout.write(stdout)
            args.stdout.close()
        if args.stderr is not None:
            args.stderr.write(stderr)
            args.stderr.close()

        sys.exit(exit_code)

    elif args.action == "spec":
        spec = evaluation_spec.EvaluationSpec()
        spec.mode = oscap_helpers.EvaluationMode.from_string(args.mode)
        spec.target = args.target
        if spec.mode not in [oscap_helpers.EvaluationMode.CVE_SCAN,
                             oscap_helpers.EvaluationMode.STANDARD_SCAN]:
            spec.input_.set_contents(args.input_.read())
        if args.tailoring is not None:
            spec.tailoring.set_contents(args.tailoring.read())

        spec.profile = args.profile
        spec.online_remediation = args.remediate

        if args.print_xml:
            print(spec.to_xml_source())
            sys.exit(0)

        else:
            results, stdout, stderr, exit_code = spec.evaluate(config)
            if args.results is not None:
                args.results.write(results)
                args.results.close()
            if args.stdout is not None:
                args.stdout.write(stdout)
                args.stdout.close()
            if args.stderr is not None:
                args.stderr.write(stderr)
                args.stderr.close()

            sys.exit(exit_code)

    elif args.action == "target-cpes":
        cpes = evaluation_spec.EvaluationSpec.detect_CPEs_of_target(
            args.target, config
        )
        print("\n".join(cpes))
        sys.exit(0)

    elif args.action == "scan":
        assert(os.path.isdir(args.output))

        targets = preprocess_targets(args.targets)

        queue = Queue.Queue(len(targets))
        for target in targets:
            queue.put_nowait(target)

        scanned_targets = []
        failed_targets = []

        def scan_worker():
            while True:
                try:
                    target = queue.get(False)

                    if len(failed_targets) > 0:
                        failed_targets.append(target)
                        queue.task_done()
                        continue

                    cve_results = None
                    standard_scan_results = None

                    logging.debug("Started scanning target '%s'", target)
                    started_time = None
                    finished_time = None

                    try:
                        started_time = datetime.datetime.now()
                        cpes = []
                        try:
                            cpes = evaluation_spec.EvaluationSpec.detect_CPEs_of_target(
                                target, config
                            )
                        except:
                            logging.exception(
                                "Failed to detect CPEs of target '%s'. "
                                "Assuming no CPEs..." % (target)
                            )

                        if not args.no_cve_scan:
                            es = evaluation_spec.EvaluationSpec()
                            es.mode = oscap_helpers.EvaluationMode.CVE_SCAN
                            es.target = target
                            es.cpe_hints = cpes
                            try:
                                cve_results, stdout, stderr, exit_code = \
                                    es.evaluate(config)

                                if exit_code == 1:
                                    logging.warning(
                                        "CVE scan of target '%s' failed with "
                                        "exit_code %i.\n\nstdout:%s\n\nstderr:%s" %
                                        (target, exit_code, stdout, stderr)
                                    )
                            except:
                                logging.exception(
                                    "Failed to scan target '%s' for "
                                    "vulnerabilities." % (target)
                                )


                        if not args.no_standard_compliance:
                            es = evaluation_spec.EvaluationSpec()
                            es.mode = oscap_helpers.EvaluationMode.STANDARD_SCAN
                            es.target = target
                            es.cpe_hints = cpes
                            try:
                                standard_scan_results, stdout, stderr, exit_code = \
                                    es.evaluate(config)

                                if exit_code == 1:
                                    logging.warning(
                                        "Standard compliance scan of target '%s' "
                                        "failed with exit_code %i.\n\nstdout:%s\n\n"
                                        "stderr:%s" %
                                        (target, exit_code, stdout, stderr)
                                    )

                            except:
                                logging.exception(
                                    "Failed to scan target '%s' for "
                                    "standard profile compliance." % (target)
                                )

                        finished_time = datetime.datetime.now()

                    except Exception as e:
                        logging.exception(e)
                        failed_targets.append(target)

                    queue.task_done()
                    scanned_targets.append(
                        (target, cve_results, standard_scan_results,
                         started_time, finished_time)
                    )

                    percent = "{0:6.2f}%".format(
                        float(len(scanned_targets) * 100) / len(targets)
                    )

                    logging.info("[%s] Scanned target '%s'", percent, target)

                except Queue.Empty:
                    break

        assert(args.jobs > 0)

        workers = []
        for worker_id in range(args.jobs):
            worker = threading.Thread(
                name="Atomic scan worker #%i" % (worker_id),
                target=scan_worker
            )
            workers.append(worker)
            worker.start()

        try:
            queue.join()

        except KeyboardInterrupt:
            failed_targets.append(None)

            for worker in workers:
                worker.join()

            sys.stderr.write("Evaluation interrupted by user!\n")

        if len(failed_targets) > 0:
            sys.stderr.write(
                "Fatal error encountered while evaluating! Failed to evaluate "
                "at least %i targets!\n" % (len(failed_targets) - 1)
            )

        for target, cve_results, standard_scan_results, \
                started_time, finished_time in scanned_targets:
            mangled_target = target
            mangled_target = mangled_target.replace(":", "_")
            mangled_target = mangled_target.replace("/", "_")

            json_target = target
            if json_target.startswith("chroot://"):
                json_target = json_target[len("chroot://"):]

            json_data = {}
            json_data["UUID"] = json_target
            json_data["Scanner"] = "openscap"
            json_data["Time"] = started_time.strftime("%Y-%m-%dT%H:%M:%S") \
                if started_time is not None else "unknown"
            json_data["Finished Time"] = \
                finished_time.strftime("%Y-%m-%dT%H:%M:%S") \
                if finished_time is not None else "unknown"
            json_data["Vulnerabilities"] = []
            if (args.no_cve_scan or cve_results) and \
                    (args.no_standard_compliance or standard_scan_results):
                json_data["Succesful"] = "true"
            else:
                json_data["Succesful"] = "false"

            scan_type = []

            if cve_results is not None:
                scan_type.append("CVE")

                summarize_cve_results(cve_results, json_data["Vulnerabilities"])

                with io.open(os.path.join(
                        args.output, mangled_target + "-cve.xml"), "w",
                        encoding="utf-8") as f:
                    f.write(cve_results)

            if standard_scan_results is not None:
                scan_type.append("Standard Compliance")

                summarize_standard_compliance_results(
                    standard_scan_results, json_data["Vulnerabilities"]
                )

                with io.open(os.path.join(
                        args.output, mangled_target + "-std.xml"), "w",
                        encoding="utf-8") as f:
                    f.write(standard_scan_results)

            json_data["Scan Type"] = ", ".join(scan_type)

            with open(os.path.join(
                    args.output, mangled_target + ".json"), "w") as f:
                json.dump(json_data, f, indent=2)


if __name__ == "__main__":
    main()
